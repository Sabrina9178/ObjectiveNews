# -*- coding: utf-8 -*-
"""CNA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K8-0wBK6HH4qVCjiQ8XfpzBFGdPd5Yb1
"""

import datetime
from selenium.webdriver.edge.options import Options
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
import random
import csv
from tqdm import tqdm

import requests
from fake_useragent import UserAgent  # 使用 fake_useragent 生成隨機標頭
import random
from bs4 import BeautifulSoup

def get_news_content(url):
    # 隨機生成標頭
    user_agent = UserAgent()
    headers = {'User-Agent': user_agent.random}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()  # 如果請求不成功，則拋出異常
        
        soup = BeautifulSoup(response.content, 'html.parser')
        content_element = soup.find('div', class_='paragraph')  # 使用 class 來找到指定 class 的標籤
        if content_element:
            news_content = "\n".join([p.text for p in content_element.find_all('p')])  # 找到所有內容段落並將其組合為一個字符串
            return news_content
        else:
            return ""  # 如果找不到內容，則返回空字符串
    except Exception as e:
        print(f"Failed to fetch news content: {e}")
        return ""

def find_CNA_news(n_hours_ago,driver):

    # 新聞網站 URL
    url = "https://www.cna.com.tw/list/aall.aspx"
    driver.get(url)

    # 找到所有含有 style 屬性的 li 元素
    li_elements = driver.find_elements(By.CSS_SELECTOR, "li[style]")

    # 將找到的元素的 style 屬性移除
    for li_element in li_elements:
        driver.execute_script("arguments[0].removeAttribute('style')", li_element)

    # 初始化一個空字典來存放時間
    news = {}
    index = 1
    # 用於存儲已找到的新聞標題
    finded_news_titles = set()

    print("CNA:")
    # 持續滾動頁面,直到找不到符合時間範圍的新聞為止
    while True:
        # 找到所有新聞項目
        news_items = driver.find_elements(By.CSS_SELECTOR, "ul#jsMainList > li")

        # 如果沒有新的新聞項目,退出循環
        if not news_items:
            break

        # 標記本次循環是否找到了符合時間範圍的新聞
        found_new_news = False

        # 遍歷每個新聞項目
        for item in news_items:
            # 獲取標題
            title_element = item.find_element(By.CSS_SELECTOR, "span")
            news_title = title_element.text if title_element else ""

            # 如果標題已經被處理過,跳過
            if news_title in finded_news_titles:
                continue

            # 獲取時間
            time_element = item.find_element(By.CSS_SELECTOR, "div.date")
            news_time_str = time_element.text if time_element else ""
            news_time = datetime.datetime.strptime(news_time_str, "%Y/%m/%d %H:%M")

            # 如果新聞時間在5小時範圍內
            if n_hours_ago <= news_time:
                found_new_news = True
                finded_news_titles.add(news_title)  # 將標題加入已處理集合

                link_element = item.find_element(By.CSS_SELECTOR,"a")
                news_link = link_element.get_attribute('href') if title_element else ""

                # print(f"標題: {news_title}")
                # print(f"連結: {news_link}")
                # print(f"時間: {news_time_str}")
                # print("-------------------")

                news[index] = [news_title,
                               news_link,
                               news_time_str,
                               ""] #空的代表category
                index += 1
            else:
                break

        # 如果本次循環中沒有找到符合時間範圍的新聞,就退出
        if not found_new_news:
            print(f"\n  stop date-time: {news_time_str}")
            break

        print(f"  found {len(news)} news, last date-time： {news[len(news)][2]}", end='\r')
        
        # 模擬換到下一頁
        view_more_btn = driver.find_element(By.CSS_SELECTOR,"a#SiteContent_uiViewMoreBtn")
        driver.execute_script("arguments[0].click();", view_more_btn)
        time.sleep(2)  # 等待頁面響應

    print("\n")
    
    return news

