# -*- coding: utf-8 -*-
"""FTVN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18ZCXfRe_bNjMYOljcdAQksEGDsah8IXY
"""

import datetime
from selenium.webdriver.edge.options import Options
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
from tqdm import tqdm

import requests
from fake_useragent import UserAgent  # 使用 fake_useragent 生成隨機標頭
import random
from bs4 import BeautifulSoup
import re

def get_news_content(url):
    # 隨機生成標頭
    user_agent = UserAgent()
    headers = {'User-Agent': user_agent.random}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()  # 如果請求不成功，則拋出異常
        
        soup = BeautifulSoup(response.content, 'html.parser')

        aphorism_elements = soup.find_all(class_="aphorism")
        for aphorism_element in aphorism_elements:
            aphorism_element.decompose()

        fig_elements = soup.find_all('figure')
        for fig_element in fig_elements:
            fig_element.decompose()

        content_element = soup.find('div', class_='article-body font-m')  # 使用 class 來找到指定 class 的標籤
        if content_element:
            news_content = "\n".join([p.text for p in content_element.find_all('p')])  # 找到所有內容段落並將其組合為一個字符串
            return news_content
        else:
            return ""  # 如果找不到內容，則返回空字符串
    except Exception as e:
        print(f"Failed to fetch news content: {e}")
        return ""

def find_FTVN_news(n_hours_ago,driver):
    
    # 新聞網站 URL
    url = "https://www.ftvnews.com.tw/realtime/"
    driver.get(url)

    # 初始化一個空字典來存放時間
    news = {}

    index = 1

    # 初始化已抓取的新聞數量
    num_news_before_scroll = 0

    # 持續滾動頁面,直到找不到符合時間範圍的新聞為止
    print("FTVN:")
    while True:

        # 找到所有新聞項目
        news_items = driver.find_elements(By.CSS_SELECTOR, 'ul#realtime div.content')

        # 如果沒有新的新聞項目,退出循環
        if not news_items:
            break

        # 標記本次循環是否找到了符合時間範圍的新聞
        found_new_news = False

        # 遍歷每個新聞項目
        for i in range(num_news_before_scroll, len(news_items)):
            item = news_items[i]
            # 獲取標題
            title_element = item.find_element(By.CSS_SELECTOR, "h2.title")
            news_title = title_element.text if title_element else ""
            # 獲取時間
            
            time_element = item.find_element(By.CSS_SELECTOR, "div.time")
            news_time_str = time_element.get_attribute('data-time') if time_element else ""
            # 判斷時間字串的格式是否與當前時間格式一致
            news_time = datetime.datetime.strptime(news_time_str, "%Y/%m/%d %H:%M:%S")
            # 如果新聞時間在n小時範圍內
            if n_hours_ago <= news_time:
                found_new_news = True

                link_element = item.find_element(By.CSS_SELECTOR, "div.content > a")
                news_link = link_element.get_attribute('href') if link_element else ""

                # print(f"標題: {news_title}")
                # print(f"連結: {news_link}")
                # print(f"時間: {news_time}")
                # print("-------------------")

                news[index] = [news_title,
                               news_link,
                               news_time_str,
                               ""] #空的代表category
                index += 1

            else:
                # 如果本次循環中沒有找到符合時間範圍的新聞,就退出
                break

        num_news_before_scroll = len(news_items)

        if not found_new_news:
            print(f"\n  stop date-time: {news_time_str}")
            break

        print(f"  found {len(news)} news, last date-time： {news[len(news)][2]}", end='\r')
        
        # 模擬滾動到頁面底部
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        driver.execute_script("window.scrollBy(0, -1);")
        time.sleep(2)  # 等待頁面響應

    print("\n")
    # 訪問每個新聞詳情頁,爬取內文
    # for index in tqdm(news, desc='Processing FTVN News'):

    #     driver.get(news[index][1])
    #     try:
    #         content_elements = driver.find_elements(By.ID, "contentarea")
    #         content_elements = driver.find_elements(By.CSS_SELECTOR, "p")
    #         news_content = "\n".join([p.text for p in content_elements])

    #         news[index].append("")
    #         news[index].append(news_content)
    #     except:
    #         news[index].append("")
    #         news[index].append("")
    #     # print(f"標題: {news[index][0]}")
    #     # # print(f"分類: {news[index][3]}")
    #     # print(f"內文: {news[index][-1]}")

    

    return news

    #關閉瀏覽器
