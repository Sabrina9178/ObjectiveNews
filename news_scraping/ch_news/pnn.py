# -*- coding: utf-8 -*-
"""PNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GDuoIGxeX62SRu2hWd4-DQPCIj50HC58
"""

import datetime
from selenium.webdriver.edge.options import Options
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
from tqdm import tqdm

import requests
from fake_useragent import UserAgent  # 使用 fake_useragent 生成隨機標頭
import random
from bs4 import BeautifulSoup

def get_news_content(url):
    # 隨機生成標頭
    user_agent = UserAgent()
    headers = {'User-Agent': user_agent.random}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()  # 如果請求不成功，則拋出異常
        
        soup = BeautifulSoup(response.content, 'html.parser')
        content_element = soup.find('div', class_='post-article text-align-left')  # 使用 class 來找到指定 class 的標籤
        if content_element:
            news_content = "\n".join([p.text for p in content_element.find_all('p')])  # 找到所有內容段落並將其組合為一個字符串
            return news_content
        else:
            return ""  # 如果找不到內容，則返回空字符串
    except Exception as e:
        print(f"Failed to fetch news content: {e}")
        return ""

def find_PNN_news(n_hours_ago,driver):

    # 新聞網站 URL
    url = "https://news.pts.org.tw/dailynews?page=1"
    driver.get(url)


    # 初始化一個空字典來存放時間
    news = {}

    index = 1

    # 用於存儲已找到的新聞標題
    finded_news_titles = set()

    print("PNN:")
    # 持續滾動頁面,直到找不到符合時間範圍的新聞為止
    while True:
        # 找到所有新聞項目
        news_items = driver.find_elements(By.CSS_SELECTOR, "li.d-flex")

        # 如果沒有新的新聞項目,退出循環
        if not news_items:
            break

        # 標記本次循環是否找到了符合時間範圍的新聞
        found_new_news = False
        #print("found",len(news_items),"news")
        # 遍歷每個新聞項目
        for item in news_items:
            
            # 獲取標題
            title_element = item.find_element(By.CSS_SELECTOR, "h2")
            news_title = title_element.get_attribute('title') if title_element else ""

            # 如果標題已經被處理過,跳過
            if news_title in finded_news_titles:
                continue

            # 獲取時間
            time_element = item.find_element(By.CSS_SELECTOR, "time")
            news_time_str = time_element.text if time_element else ""
            news_time = datetime.datetime.strptime(news_time_str, "%Y-%m-%d %H:%M")

            # 如果新聞時間在n小時範圍內
            if n_hours_ago <= news_time:
                found_new_news = True
                    
                finded_news_titles.add(news_title)  # 將標題加入已處理集合

                link_element = item.find_element(By.CSS_SELECTOR, "h2 > a")
                news_link = link_element.get_attribute('href') if link_element else ""
                
                try:
                    category_element = item.find_element(By.CSS_SELECTOR, "div.news-info.news-info- > a")
                    news_category = category_element.text if category_element else ""
                except:
                    news_category = ""

                # print(f"標題: {news_title}")
                # print(f"連結: {news_link}")
                # print(f"時間: {news_time_str}")
                # print(f"分類: {news_category}")
                # print("-------------------")

                news[index] = [news_title, 
                               news_link, 
                               news_time_str, 
                               news_category]
                index += 1
                
            else:
                break
        
        # 如果本次循環中沒有找到符合時間範圍的新聞,就退出
        if not found_new_news:
            print(f"\n  stop date-time: {news_time_str}")
            break
            
        target_element = driver.find_element(By.CSS_SELECTOR, 'a[class="cursor-default"]')
        next_element = target_element.find_element(By.XPATH, './following::li[1]/a')
        link_href = next_element.get_attribute("href")
        driver.get(link_href)
            
        print(f"  found {len(news)} news, last date-time： {news[len(news)][2]}", end='\r')

    print("\n")
    # 訪問每個新聞詳情頁,爬取內文
    # for index in tqdm(news, desc='Processing PNN News'):

    #     driver.get(news[index][1])
    #     content_elements = driver.find_elements(By.CSS_SELECTOR, "p")
    #     news_content = "\n".join([p.text for p in content_elements])

    #     news[index].append(news_content)
    #     # print(f"標題: {news[index][0]}")
    #     # print(f"內文: {news[index][-1]}")

    

    return news


