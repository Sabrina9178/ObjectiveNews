# -*- coding: utf-8 -*-
"""CNA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K8-0wBK6HH4qVCjiQ8XfpzBFGdPd5Yb1
"""

import datetime
from selenium.webdriver.edge.options import Options
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
import random
import csv
from tqdm import tqdm

import requests
from fake_useragent import UserAgent  # 使用 fake_useragent 生成隨機標頭
import random
from bs4 import BeautifulSoup
import re

def get_news_content(url,now_time):
# 爬取日報的內文
    # 隨機生成標頭
    user_agent = UserAgent()
    headers = {'User-Agent': user_agent.random}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()  # 如果請求不成功，則拋出異常
        
        soup = BeautifulSoup(response.content, 'html.parser')
        del_elements = soup.find_all(['small','strong'])
        for del_element in del_elements:
            del_element.decompose()
        
        article_div = soup.find('div', itemprop="articleBody")

        news = {}
        index = 0
        for tag in article_div:
            if tag.name == "h2":
                index += 1
                news[index] = [tag.text,
                               url,
                               now_time,
                               "",
                               ""]
            elif (tag.name == "p" or tag.name == "a")and tag.text != "":
                news[index][4] += tag.text
        print("done!")
        return news

    except Exception as e:
        print(f"Failed to fetch news content: {e}")
        return ""

def find_Initium_news(now):
    print("Initium：")
    now_time = now.strftime("%Y%m%d")
    url = f"https://theinitium.com/article/" + now_time + "-daily-brief"
    news = get_news_content(url,now_time)

    return news